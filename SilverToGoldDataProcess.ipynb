{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:18.1353298Z",
              "execution_start_time": "2024-08-30T15:50:17.6016128Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "01dcd36c-9e8e-4c65-9391-5298725d2abf",
              "queued_time": "2024-08-30T15:50:17.4516709Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 8,
              "statement_ids": [
                8
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 8, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyspark'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define paths\u001b[39;00m\n\u001b[0;32m      4\u001b[0m silver_base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Define paths\n",
        "silver_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/silver/fintech/\"\n",
        "output_base_path = \"abfss://fintechcontainer@fintechstorageaccount.dfs.core.windows.net/gold/fintech/\"\n",
        "\n",
        "# Load data from the silver layer\n",
        "accounts_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Accounts/\")\n",
        "customers_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Customers/\")\n",
        "loans_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Loans/\")\n",
        "payments_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Payments/\")\n",
        "transactions_df = spark.read.format(\"delta\").load(f\"{silver_base_path}Transactions/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:23.5932296Z",
              "execution_start_time": "2024-08-30T15:50:18.2777553Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "aae8a35f-9e1b-474d-a27a-cfbf5e4965ef",
              "queued_time": "2024-08-30T15:50:17.4981663Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 9,
              "statement_ids": [
                9
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 9, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dim_customers_df = customers_df.select(\n",
        "    col(\"CustomerID\").alias(\"customer_id\"),\n",
        "    col(\"FirstName\").alias(\"first_name\"),\n",
        "    col(\"LastName\").alias(\"last_name\"),\n",
        "    col(\"Email\").alias(\"email\"),\n",
        "    col(\"PhoneNumber\").alias(\"phone_number\"),\n",
        "    col(\"Address\").alias(\"address\"),\n",
        "    col(\"City\").alias(\"city\"),\n",
        "    col(\"State\").alias(\"state\"),\n",
        "    col(\"Country\").alias(\"country\"),\n",
        "    col(\"ZipCode\").alias(\"zip_code\"),\n",
        "    col(\"SignupDate\").alias(\"signup_date\")\n",
        ")\n",
        "\n",
        "dim_customers_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_customers/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:29.1370214Z",
              "execution_start_time": "2024-08-30T15:50:23.7276848Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "99d6b762-a356-49ab-b89f-328a7fbe7318",
              "queued_time": "2024-08-30T15:50:17.547399Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 10,
              "statement_ids": [
                10
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 10, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dim_accounts_df = accounts_df.select(\n",
        "    col(\"AccountID\").alias(\"account_id\"),\n",
        "    col(\"AccountType\").alias(\"account_type\"),\n",
        "    col(\"Balance\").alias(\"balance\"),\n",
        "    col(\"OpenDate\").alias(\"open_date\"),\n",
        "    col(\"AccountAgeYears\").alias(\"account_age_years\")\n",
        ")\n",
        "\n",
        "dim_accounts_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_accounts/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:33.2622088Z",
              "execution_start_time": "2024-08-30T15:50:29.299071Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "7e805b00-f63e-4cd2-803b-849ef2f28f0c",
              "queued_time": "2024-08-30T15:50:17.5996913Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 11,
              "statement_ids": [
                11
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 11, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dim_loans_df = loans_df.select(\n",
        "    col(\"LoanID\").alias(\"loan_id\"),\n",
        "    col(\"LoanType\").alias(\"loan_type\"),\n",
        "    col(\"LoanAmount\").alias(\"loan_amount\"),\n",
        "    col(\"InterestRate\").alias(\"interest_rate\"),\n",
        "    col(\"LoanStartDate\").alias(\"loan_start_date\"),\n",
        "    col(\"LoanEndDate\").alias(\"loan_end_date\"),\n",
        "    col(\"TotalInterest\").alias(\"total_interest\"),\n",
        "    col(\"LoanDurationYears\").alias(\"loan_duration_years\")\n",
        ")\n",
        "\n",
        "dim_loans_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}dim_loans/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:42.097262Z",
              "execution_start_time": "2024-08-30T15:50:33.4124288Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "0ed8f51f-b136-4c4d-991d-4ef939b8ccfc",
              "queued_time": "2024-08-30T15:50:17.7759174Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 12,
              "statement_ids": [
                12
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 12, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fact_payments_df = payments_df \\\n",
        "    .join(loans_df.select(\"LoanID\", \"CustomerID\"), \"LoanID\") \\\n",
        "    .select(\n",
        "        col(\"PaymentID\").alias(\"payment_id\"),\n",
        "        col(\"LoanID\").alias(\"loan_id\"),\n",
        "        col(\"CustomerID\").alias(\"customer_id\"),\n",
        "        col(\"PaymentDate\").alias(\"payment_date\"),\n",
        "        col(\"PaymentAmount\").alias(\"payment_amount\"),\n",
        "        col(\"PaymentMethod\").alias(\"payment_method\")\n",
        "    )\n",
        "\n",
        "fact_payments_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_payments/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2024-08-30T15:50:47.5380183Z",
              "execution_start_time": "2024-08-30T15:50:42.2253683Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "798b26a4-980e-4667-8526-25279d046616",
              "queued_time": "2024-08-30T15:50:18.2160766Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "gdssparkpool",
              "state": "finished",
              "statement_id": 13,
              "statement_ids": [
                13
              ]
            },
            "text/plain": [
              "StatementMeta(gdssparkpool, 6, 13, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fact_transactions_df = transactions_df \\\n",
        "    .join(accounts_df.select(\"AccountID\", \"CustomerID\"), \"AccountID\") \\\n",
        "    .select(\n",
        "        col(\"TransactionID\").alias(\"transaction_id\"),\n",
        "        col(\"AccountID\").alias(\"account_id\"),\n",
        "        col(\"CustomerID\").alias(\"customer_id\"),\n",
        "        col(\"TransactionDate\").alias(\"transaction_date\"),\n",
        "        col(\"Amount\").alias(\"amount\"),\n",
        "        col(\"TransactionType\").alias(\"transaction_type\"),\n",
        "        col(\"Description\").alias(\"description\")\n",
        "    )\n",
        "\n",
        "fact_transactions_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}fact_transactions/\")\n"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
